\documentclass[xcolor=dvipsnames]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{soul}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{cancel}
\usepackage[percent]{overpic}
\usepackage{listings}
\usepackage{color}
\lstset{ %
  language=Python,
  basicstyle=\ttfamily\tiny,
  emphstyle=\color{red},
  keywordstyle=\color{black}\bfseries,
  identifierstyle=\color{DarkOrchid}\ttfamily,
  commentstyle=\color{Brown}\rmfamily\itshape,
  stringstyle=\color{blue}\slshape,
  showstringspaces=false,
  frame=single,                   % adds a frame around the code
}

\setbeamertemplate{navigation symbols}{}
\useoutertheme{infolines}
\usecolortheme[named=violet]{structure}
\setbeamertemplate{items}[circle]

\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\title[Data Handling]{CCD Acceptance Testing Data Handling}
\author{Brett Viren and Tom Throwe}
\institute[BNL]
{
  Physics Department

  \includegraphics[height=1.5cm]{bnl-logo}
}

\date{\today}

\definecolor{rootpink}{RGB}{255,0,255}
\definecolor{macroyellow}{RGB}{255,215,0}

\hypersetup{
  pdfkeywords={},
  pdfsubject={},
  pdfcreator={pdflatex, beamer and emacs the digital blood, sweat and tears}}

\begin{document}

\maketitle

\begin{frame}
\frametitle{Outline}
\tableofcontents
\end{frame}

\begin{frame}
  \LARGE
  \begin{center}
    Caveat: a work in progress \\
    (but some progress in work).
  \end{center}
\end{frame}

\section{Overview}

\begin{frame}[fragile]
  \frametitle{High Level Data Flow}
  \includegraphics[width=\textwidth]{dataflow}
  \begin{enumerate}
  \item Test station / analyzer produces result files.
  \item All result files are stored ``permanently'' to a well defined disk location.
  \item Specially formatted result summary files are validated, parsed
    and their contents are uploaded to the database.
  \end{enumerate}

  \footnotesize
  By using intermediate files in a common, popular format we can make
  a loose coupling between the test stations and analyzers and the
  database.  This will make supporting the varied test platforms and
  environments simpler.
\end{frame}

\section{Job Harness}

\begin{frame}[fragile]
  \frametitle{Job Harness - Version Control}
  \begin{columns}
    \begin{column}{0.5\paperwidth}
      Assure knowledge of what software was run to produce any given
      result.
      \begin{itemize}
      \item Tests run by a common job harness (Linux and Windows).
      \item Operator enters external parameters defining a run which
        are captured in the output.
      \item Station software from a specific (GIT) commit is checked out.
      \item Test jobs run producing results.
      \item Any post-processing to produce required file format.
      \end{itemize}
    \end{column}
    \begin{column}{0.5\paperwidth}
      \includegraphics[width=\textwidth]{job-harness}
    \end{column}
  \end{columns}

  \vspace{2mm}

  $\rightarrow$Currently at the conceptual level.
\end{frame}

\section{Test Result Files}

\begin{frame}
  \frametitle{Station Results}

  A station / analyzer produces result files in three categories:

  \begin{columns}
    \begin{column}{0.5\paperwidth}
      \footnotesize
      \begin{description}
      \item[Metadata FITS] Describes test software and enumerates results
        files and any auxiliary files.  (well defined schema)
      \item[Result FITS] Result summary files to be parsed and uploaded
        into the DB. (well defined schema)
      \item[Auxiliary] Any additional files to archive. (arbitrary
        formats)
      \end{description}
    \end{column}
    \begin{column}{0.4\paperwidth}
      \includegraphics[width=\textwidth]{files}
    \end{column}
  \end{columns}
  All files are archived, first two types are parsed into LIMS.

\end{frame}

\begin{frame}
  \frametitle{Metadata FITS File} 

  Collects information about all result files.  Here a ``test'' means
  a run on a test station or an offline analysis.  

  Contains 4 HDUs:

  \begin{enumerate}
  \item Primary HDU, header only, (this will likely expand)
    \begin{description}
    \item[\texttt{TESTNAME}] a canonical name for the test.
    \item[\texttt{DATE-OBS}] UTC time stamp for when the test was run.
    \item[\texttt{USERNAME}] Name for the test station operator or analyzer.
    \end{description}
  \item Test's software description consisting of list of main
    programs and their GIT SHA1 commit hash and tag.  Lists are stored
    in a FITS table.
  \item List of FITS files to be parsed by LIMS (see next).  Stored as
    a table of filenames and content SHA1 digest hashes.
  \item List of all auxiliary files to be linked into the LIMS
    database.  Lists stored in same form as \#3.
  \end{enumerate}

\end{frame}


\begin{frame}
  \frametitle{Result FITS File}
  Collects all result data that will be parsed into LIMS's DB.

  \vspace{2mm}

  Extends a base schema:
  \begin{enumerate}
  \item Common PrimaryHDU for all tests.
    \begin{description}
    \item[\texttt{TESTNAME}] Canonical name for the test as a whole.
    \item[\texttt{EXTNAME}] the HDU schema name
    \item[\texttt{EXTVER}] this HDU's schema version
    \end{description}
  \item Test-specific secondary HDUs with some common cards:
    \begin{description}
    \item[\texttt{EXTNAME}] the HDU schema name
    \item[\texttt{EXTVER}] this HDU's schema version
    \item[...] all additional header cards and/or table columns needed
      to hold part of a result
    \end{description}
  \item Etc, as many secondary HDUs as needed to hold a test's result. 
    \begin{itemize}
    \item Each HDU follows a well defined schema.
    \end{itemize}
  \end{enumerate}


\end{frame}

\begin{frame}
  \frametitle{Example - JimF's Gain/Noise/ColdSpot}
  This result fits into 5 HDUs:
  \begin{description}
  \item[\texttt{Primary}] Common primary HDU
  \item[\texttt{FileRefs}] Table HDU holding columns for file paths and
    one for file checksum (SHA1) to record input files.
  \item[\texttt{Gains}] Table HDU holding two columns of floats, one
    for each gain measurement type.
  \item[\texttt{Noises}] Table HDU holding two columns of floats, one
    for each noise measurement type.
  \item[\texttt{ColdSpot}] Table HDU holding four columns of ints,
    amp\#, pixel count, spot X and spot Y.
  \item[\texttt{LinRange}] Min/max where each amp is within linear
    specs (to be added)
  \item[\texttt{FullWell}] Point at which each amp ``blows up''. (to
    be added)
  \end{description}

  \vspace{5mm}

  \tiny
  (this is out of date by about a week)

\end{frame}


\section{Schema Representation In Python}

\begin{frame}
  \frametitle{Schema Definition in Python}

  Implementing a FITS schema in Python

  \vspace{5mm}

  \begin{enumerate}
  \item Subclass \texttt{pyfits} HDU classes to 
    \begin{itemize}
    \item[$\Rightarrow$] valid low-level FITS format, by construction.
    \end{itemize}
  \item Add a \texttt{validate()} method.
    \begin{itemize}
    \item Basic validation in intermediate subclasses
    \item Additional validation in further, per-test subclasses
    \end{itemize}
  \item One Python module for each test result
    \begin{itemize}
    \item  Schema defined as hard-coded list of classes
    \end{itemize}
  \item Replace \texttt{pyfits.open()} to allow customized classes to
    be used when reading in FITS files.
  \end{enumerate}

\end{frame}

\begin{frame}
  \frametitle{Current Status of Implementation}

  Status:
  \begin{itemize}
  \item Basic skeleton exists.
  \item Unit tests written with partial coverage.
  \item Metadata file schema implemented.
  \item JimF's photon transfer curve linearity results partially
    implemented
    \begin{itemize}
    \item Result specification still ongoing
    \item Jim will likely be first Guinea Pig to use schema classes directly
    \end{itemize}
  \item Some basic validation code written for the existing schema. 
  \item Documentation at:\\
    {\footnotesize
    \url{http://www.phy.bnl.gov/~bviren/lsst/lcatr/doc/lcatr/build/html/}}
  \item Code at:\\
    {\footnotesize
    \url{https://github.com/brettviren/lcatr}}
  \end{itemize}

\end{frame}


\begin{frame}[fragile]
  \frametitle{Example: The Metadata schema}

  Construct an unfilled schema (only convention-required content added).

  \begin{lstlisting}[emph={required_cards,required_columns,schema}]
class LimsMetaPrimaryHDU(pyfits.PrimaryHDU):
    required_cards = [
        ('TESTNAME','Canonical name for the test result'),
        ('DATE-OBS','Time stamp of when test is run'),
        ('USERNAME','Name of operator/analyzer performing test'),
        ]
# ...
class LimsMetaSoftwareTableHDU(pyfits.BinTableHDU):
    required_columns = [
        ('CommitHash','A64', 'The SHA1 hash of the GIT commit providing the software'), 
        ('CommitTag', 'A64', 'The corresponding GIT commit tag'),   
        ('RepoURL', 'A64', 'The URL pointing at the GIT repository'),  
        ('ProgPath', 'A64', 'Path rooted in the repository to the main program'),   
        ('CmdLine', 'A64', 'The command line argument string given to the main program'),    
        ('ExitCode', 'J', 'The exit return code'),
        ]
# ... [snip] ... #
schema = [LimsMetaPrimaryHDU,LimsMetaSoftwareTableHDU,
          LimsMetaResultFilesHDU,LimsMetaAuxiliaryFilesHDU]
  \end{lstlisting}
  \footnotesize
  \begin{itemize}
  \item Primary and first secondary HDU shown
  \item Most schema defines required cards/columns and provides any
    required card values.
  \item Full schema for the file is defined as a list of HDU classes.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Example of Filling the GNC Schema}
  
  Filling from code:
  \begin{lstlisting}
hdus = pyfits.HDUList([
  lcatr.limsmeta.schema[0](
    testname = 'TestLimsMetaData',
    date_obs = datetime.datetime(*time.gmtime()[:6]),
    username = os.environ.get('USER','testuser')),

lcatr.limsmeta.schema[1](
  commithash = [sha1().hexdigest(),],
  committag = ['TheGitTag',],
  repourl = ['git://github.com/brettviren/lcatr/',],
  progpath = ['test1/mainprog',],
  cmdline = ['./test1/mainprog arg1 arg2',],
  exitcode = [0,]),
  \end{lstlisting}

  Fill at construction time using card or column names as keyword arguments.

  \vspace{3mm}

  Or, use schema aware version of \texttt{pyfits.open()} fill from file.

  \begin{lstlisting}
    import lcatr        # replaces/overrides parts of pyfits
    import pyfits
    f = pyfits.open("testfile.fits")
    f.validate()
  \end{lstlisting}
\end{frame}

\section{To Do}

\begin{frame}
  \frametitle{To Do}
  \begin{itemize}
  \item Still understanding the result data from the test stations and analyses.
    \begin{itemize}
    \item Not practical to use the Python schema directly in all cases.
    \item Will develop conversion/summation scripts in these cases.
    \end{itemize}
  \item Schema evolution handling needs implementing.
  \item Job harness system at the concept stage.
    \begin{itemize}
    \item Will leverage GIT and environment ``modules''.
    \end{itemize}
  \item Still fuzzy on:
    \begin{itemize}
    \item How to handle calibration information?
    \item How to handle environment monitoring data?
    \end{itemize}
  \end{itemize}
\end{frame}

\end{document}

